{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4b2ea4a-6c42-47d3-afd7-65d86a8d1590",
   "metadata": {},
   "source": [
    "Name: Stamatios Sideris\n",
    "\n",
    "ID: f2822113"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19e3636-df06-4f74-87ea-d226f71dbf0f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### We first create a sparkSession. It is responsible to create a sparkContext object that will help us communicate with Spark. As it will need the credentials of our application it also creates a SparkConf object that includes our application name and the location it will run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25642c57-bd6a-462b-8e70-fc10267e40c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "appName = \"task3\" #determine the name of the App\n",
    "master = \"local\" #determine it will run locally\n",
    "spark = SparkSession.builder.appName(appName).master(master).getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b554f9-0387-4e7f-867c-ee599e96e1cd",
   "metadata": {
    "tags": []
   },
   "source": [
    "### We read the json file and print its schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ed685fa-7dd2-49f9-92e6-570f4d86b55c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- asin: string (nullable = true)\n",
      " |-- authors: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- author_id: string (nullable = true)\n",
      " |    |    |-- role: string (nullable = true)\n",
      " |-- average_rating: string (nullable = true)\n",
      " |-- book_id: string (nullable = true)\n",
      " |-- country_code: string (nullable = true)\n",
      " |-- description: string (nullable = true)\n",
      " |-- edition_information: string (nullable = true)\n",
      " |-- format: string (nullable = true)\n",
      " |-- image_url: string (nullable = true)\n",
      " |-- is_ebook: string (nullable = true)\n",
      " |-- isbn: string (nullable = true)\n",
      " |-- isbn13: string (nullable = true)\n",
      " |-- kindle_asin: string (nullable = true)\n",
      " |-- language_code: string (nullable = true)\n",
      " |-- link: string (nullable = true)\n",
      " |-- num_pages: string (nullable = true)\n",
      " |-- popular_shelves: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- count: string (nullable = true)\n",
      " |    |    |-- name: string (nullable = true)\n",
      " |-- publication_day: string (nullable = true)\n",
      " |-- publication_month: string (nullable = true)\n",
      " |-- publication_year: string (nullable = true)\n",
      " |-- publisher: string (nullable = true)\n",
      " |-- ratings_count: string (nullable = true)\n",
      " |-- series: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- similar_books: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- text_reviews_count: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- title_without_series: string (nullable = true)\n",
      " |-- url: string (nullable = true)\n",
      " |-- work_id: string (nullable = true)\n",
      "\n",
      "+----------+-------------+--------------+--------+------------+--------------------+-------------------+---------+--------------------+--------+----------+------+-----------+-------------+--------------------+---------+--------------------+---------------+-----------------+----------------+--------------------+-------------+--------------------+--------------------+------------------+--------------------+--------------------+--------------------+--------+\n",
      "|      asin|      authors|average_rating| book_id|country_code|         description|edition_information|   format|           image_url|is_ebook|      isbn|isbn13|kindle_asin|language_code|                link|num_pages|     popular_shelves|publication_day|publication_month|publication_year|           publisher|ratings_count|              series|       similar_books|text_reviews_count|               title|title_without_series|                 url| work_id|\n",
      "+----------+-------------+--------------+--------+------------+--------------------+-------------------+---------+--------------------+--------+----------+------+-----------+-------------+--------------------+---------+--------------------+---------------+-----------------+----------------+--------------------+-------------+--------------------+--------------------+------------------+--------------------+--------------------+--------------------+--------+\n",
      "|B00NLXQ534|[{8551671, }]|          4.12|25742454|          US|Lillian Ann Cross...|                   |         |https://s.gr-asse...|    true|          |      |           |             |https://www.goodr...|         |[{228, to-read}, ...|               |                 |                |                    |            1|                  []|[25653153, 256991...|                 1|The Switchblade M...|The Switchblade M...|https://www.goodr...|42749946|\n",
      "|          |[{3274315, }]|          3.94|30128855|          US|Florence Dupre La...|                   |         |https://images.gr...|   false|2205073346|      |           |          fre|https://www.goodr...|         |[{2, bd}, {2, to-...|             22|                1|            2016|             Dargaud|           16|                  []|                  []|                 2|             Cruelle|             Cruelle|https://www.goodr...|50558228|\n",
      "|          |  [{37450, }]|          4.28|13571772|          US|The questions pla...|                   |Hardcover|https://images.gr...|   false|          |      |           |          eng|https://www.goodr...|      146|[{493, to-read}, ...|               |                 |            2012|Hachette Partwork...|           51|[246830, 362583, ...|[13590139, 105963...|                 5|Captain America: ...|Captain America: ...|https://www.goodr...|  102217|\n",
      "+----------+-------------+--------------+--------+------------+--------------------+-------------------+---------+--------------------+--------+----------+------+-----------+-------------+--------------------+---------+--------------------+---------------+-----------------+----------------+--------------------+-------------+--------------------+--------------------+------------------+--------------------+--------------------+--------------------+--------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "json_path = \"books_5000.json\"\n",
    "df = spark.read.json(json_path)\n",
    "df.printSchema()\n",
    "df.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d129857-e6ce-468d-93d8-8fb54d53b1c1",
   "metadata": {},
   "source": [
    "### Variables language_code, publication_year and num_pages include 1685, 1072 and 1382 missing values we need to handle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c0f1074-abfa-4cae-b6ea-960b40f95ada",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1685, 1072, 1382]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[df.filter(df.language_code == \"\").count(), df.filter(df.publication_year == \"\").count(), df.filter(df.num_pages == '').count()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1fe86fd-e652-4b04-bf1b-3213013778cf",
   "metadata": {},
   "source": [
    "### To do so, we substitute the missing values with NAs for variables language_code and publication_year as we will handle as categorical moving forward, and we substitute the missing values with 0 for variable num_pages as we will handle it as numeric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6e23024-15c8-4f85-aaa3-f87790f29f7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------------+---------+\n",
      "|language_code|publication_year|num_pages|\n",
      "+-------------+----------------+---------+\n",
      "|           NA|              NA|        0|\n",
      "|          fre|            2016|        0|\n",
      "|          eng|            2012|      146|\n",
      "|          eng|              NA|        0|\n",
      "|        en-US|            1997|      272|\n",
      "|           NA|            2007|      206|\n",
      "|          eng|            2016|      224|\n",
      "|           NA|            2016|      160|\n",
      "|           NA|            2016|      160|\n",
      "|           NA|            2016|      144|\n",
      "|          kor|            2014|      212|\n",
      "|          eng|            2011|      144|\n",
      "|          eng|            2012|      200|\n",
      "|           NA|            2012|      230|\n",
      "|           NA|              NA|        0|\n",
      "|          jpn|            2013|      157|\n",
      "|          spa|            2006|      224|\n",
      "|          zho|            2011|      176|\n",
      "|           NA|            2006|      192|\n",
      "|          eng|              NA|      192|\n",
      "+-------------+----------------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import when\n",
    "df = df.withColumn(\"language_code\", when(df.language_code == \"\" ,\"NA\").otherwise(df.language_code))\n",
    "df = df.withColumn(\"publication_year\", when(df.publication_year == \"\" ,\"NA\").otherwise(df.publication_year))\n",
    "df = df.withColumn(\"num_pages\", when(df.num_pages == \"\" ,0).otherwise(df.num_pages))\n",
    "df.select(df[\"language_code\"], df[\"publication_year\"], df[\"num_pages\"]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3edc9d-052f-4e43-8f2e-f70a396d072f",
   "metadata": {},
   "source": [
    "### We change the variables types of ratings_count and num_pages to integer and average_rating to double as it is more appropriate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db8863ca-3ac3-481f-b5f3-13a6125fe409",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "df = df.withColumn(\"average_rating\",df.average_rating.cast(DoubleType()))\n",
    "df = df.withColumn(\"ratings_count\",df.ratings_count.cast(IntegerType()))\n",
    "df = df.withColumn(\"num_pages\",df.num_pages.cast(IntegerType()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a8a25de-4569-4008-bb90-f60638f41358",
   "metadata": {},
   "source": [
    "### We split the dataset by 80-20 to training and testing. We use cache command to the training dataset as it will be used multiple times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f51e7812-3498-450d-b226-b2b843def5d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4041\n",
      "958\n"
     ]
    }
   ],
   "source": [
    "trainDF, testDF = df.randomSplit([0.8, 0.2], seed=42)\n",
    "print(trainDF.cache().count()) \n",
    "print(testDF.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ebf5869-339c-4c9d-8e34-83b5ae6af400",
   "metadata": {
    "tags": []
   },
   "source": [
    "### As variable language_code is a categorical variable we must change it to numeric for our algorithm to understand. To do so, we will use the StringIndexer that will convert each distinct category to numeric starting by giving to the most appeared category the number 0. We will treat variable publication_year the same way as we do not pay attention to the time-series. We will then pass the new numeric variables to the OneHotEncoder in order to create dummy variables of 0 and 1 for the categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1640c735-6a49-4a40-9a6f-302e004dd481",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder\n",
    "\n",
    "# We determine which of the columns are categorical.\n",
    "categoricalCols = [\"language_code\", \"publication_year\"]\n",
    "\n",
    "# The following two lines are estimators. They return functions that we will later apply to transform the dataset.\n",
    "stringIndexer = StringIndexer(inputCols=categoricalCols, outputCols=[x + \"Index\" for x in categoricalCols]).setHandleInvalid(\"keep\")\n",
    "encoder = OneHotEncoder(inputCols=stringIndexer.getOutputCols(), outputCols=[x + \"OHE\" for x in categoricalCols]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a882c42-8133-4caf-8cb5-25cc3746ad00",
   "metadata": {},
   "source": [
    "### The algorithm we will use requires a single features column as input. We use VectorAssembler to create a single vector column from a list of the features we will use for the prediction. Our final dataset has 2 columns: features (that includes predictors) and average_rating (the variable we want to predict). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dffef57b-0b82-4d0a-a7ba-039d6be7e038",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "# This includes both the numeric columns and the one-hot encoded binary vector columns in our dataset.\n",
    "numericCols = [\"num_pages\", \"ratings_count\"]\n",
    "assemblerInputs = [c + \"OHE\" for c in categoricalCols] + numericCols\n",
    "vecAssembler = VectorAssembler(inputCols=assemblerInputs, outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf51265-2d97-4cc1-a74c-f4b159674186",
   "metadata": {},
   "source": [
    "### Define the linear regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c52f5e7-ce92-4cf2-8c9f-273e4929ccc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "lr = LinearRegression(featuresCol=\"features\", labelCol=\"average_rating\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7370e421-288a-47ca-832c-cd0aeb0fe219",
   "metadata": {},
   "source": [
    "### We create a pipeline that will run all the above commands we prepared to get the train dataset ready for the training of our model. Then it will train our model. Finally, we use the trained model to make predictions using the testing dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "591cefb5-62f2-467b-bd36-271c19b4c894",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "\n",
    "# Define the pipeline based on the stages created in previous steps.\n",
    "pipeline = Pipeline(stages=[stringIndexer, encoder, vecAssembler, lr])\n",
    "\n",
    "# Define the pipeline model.\n",
    "pipelineModel = pipeline.fit(trainDF)\n",
    "\n",
    "# Apply the pipeline model to the test dataset to classify the respective samples.\n",
    "predDF = pipelineModel.transform(testDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "badd124f-16b1-4539-8bd7-6b80f9e554f0",
   "metadata": {},
   "source": [
    "### The R2 for our model is very low meaning that our model is very bad at predicting the average rating of each book."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "475557ed-c21d-4ef0-ba38-7fb63cc8da37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2: 0.02223652980479096\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "mcEvaluator = RegressionEvaluator(predictionCol=\"prediction\", labelCol=\"average_rating\",metricName=\"r2\")\n",
    "print(f\"R2: {mcEvaluator.evaluate(predDF)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
